{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Predicting Career Satisfaction From Stack Overflow Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning 2018 Stack Overflow Developer Survey Data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Read the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('../survey_results_public.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Clean the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Choose a subset of variables from the dataset for training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before dropna:  (98855, 7)\n",
      "shape after dropna:  (43962, 7)\n"
     ]
    }
   ],
   "source": [
    "X_subset = dataset[[\n",
    "               'CareerSatisfaction',\n",
    "               'FrameworkWorkedWith',\n",
    "               'OperatingSystem',\n",
    "               'NumberMonitors',\n",
    "               'StackOverflowHasAccount',\n",
    "               'HoursComputer',\n",
    "               'HoursOutside'\n",
    "]]\n",
    "\n",
    "print('shape before dropna: ', X_subset.shape)\n",
    "# drop any rows with null data\n",
    "X_subset = X_subset.dropna()\n",
    "print('shape after dropna: ', X_subset.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### Separate CareerSatisfaction (what we want to predict) from the rest of the columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load the career satisfaction column into y\n",
    "y = X_subset['CareerSatisfaction']\n",
    "X_subset = X_subset.drop('CareerSatisfaction', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### Create dummies / one-hot encode y\n",
    "Each person could choose 1 of 7 ways to rate their career satisfaction.\n",
    "\n",
    "To simplify the data for ML algorithms, we will split this single column into 7 different columns, one for each category of response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43962,)\n",
      "(43962, 7)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "y = pd.get_dummies(y)\n",
    "# notice the shape after creating dummies is (43962, 7), because get_dummies() created a new column for each category of answer in the survey\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### For the `FrameworkWorkedWith` column, one-hot encode each answer\n",
    "\n",
    "The responses in the `FrameworkWorkedWith` column correspond to a semicolon separated list (e.g `.NET Core;Spark`).\n",
    "The goal of this section of the code is twofold:\n",
    "1. find all the Frameworks which respondents were able to choose from\n",
    "2. turn each string response into a one-hot encoded vector (e.g. `.NET Core;Spark` becomes `[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(categories, data):\n",
    "    '''\n",
    "    takes in a list of categories and a list of data and returns a one-hot encoded vector \n",
    "    :param categories: \n",
    "    :param data: \n",
    "    :return: \n",
    "    '''\n",
    "    one_hot_vector = [0 for _ in range(len(categories))] # initialize a vector with 0s for each category\n",
    "    for item in data:\n",
    "        for i, category in enumerate(categories):\n",
    "            if item == category:\n",
    "                one_hot_vector[i] = 1\n",
    "    return one_hot_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# start by getting every possible category of response\n",
    "set_of_responses = set()\n",
    "for resp in X_subset['FrameworkWorkedWith']:\n",
    "    # parse the response into a list of values\n",
    "    resp_list = resp.split(';')\n",
    "    # add to the set of total responses\n",
    "    resp_set = set(resp_list)\n",
    "    set_of_responses.update(resp_set)\n",
    "# put the frameworks in alphabetical order for prettiness\n",
    "sorted_set_of_responses = sorted(set_of_responses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that we've parsed all the responses from semi-colon separated strings into arrays and found all the categories of responses for the FrameworkWorkedWith column, we can one-hot encode it easily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   .NET Core  Angular  Cordova  Django  Hadoop  Node.js  React  Spark  Spring  \\\n",
      "0          0        0        0       1       0        0      1      0       0   \n",
      "1          0        0        0       1       0        0      0      0       0   \n",
      "5          0        1        0       0       0        1      0      0       0   \n",
      "6          0        0        0       0       0        1      1      0       0   \n",
      "7          0        1        0       0       0        1      0      0       0   \n",
      "\n",
      "   TensorFlow  Torch/PyTorch  Xamarin  \n",
      "0           0              0        0  \n",
      "1           0              0        0  \n",
      "5           0              0        0  \n",
      "6           0              0        0  \n",
      "7           0              0        0  \n"
     ]
    }
   ],
   "source": [
    "# iterate thru responses once more to map the list of responses into one-hot encoded columns\n",
    "data = {}\n",
    "for i, resp in X_subset['FrameworkWorkedWith'].iteritems():\n",
    "    resp_list = resp.split(';')\n",
    "    one_hot_vector = one_hot_encode(list(sorted_set_of_responses) , resp_list)\n",
    "    data[i] = one_hot_vector\n",
    "\n",
    "# build a new dataframe that will replace the FrameworkWorkedWith column with the dict we just built\n",
    "framework_col_replacement = pd.DataFrame().from_dict(data, orient='index', columns=list(sorted_set_of_responses))\n",
    "print(framework_col_replacement.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Now replace the FrameworkWorkedWith column with the new one hot encoded df we just built\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_subset_no_framework_col = X_subset.drop('FrameworkWorkedWith', axis=1)\n",
    "X_subset_with_one_hot_df = pd.concat([X_subset_no_framework_col, framework_col_replacement], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create dummies for the rest of the categorical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final, cleaned features we will train on:\n",
      "['.NET Core' 'Angular' 'Cordova' 'Django' 'Hadoop' 'Node.js' 'React'\n",
      " 'Spark' 'Spring' 'TensorFlow' 'Torch/PyTorch' 'Xamarin'\n",
      " 'OperatingSystem_BSD/Unix' 'OperatingSystem_Linux-based'\n",
      " 'OperatingSystem_MacOS' 'OperatingSystem_Windows' 'NumberMonitors_1'\n",
      " 'NumberMonitors_2' 'NumberMonitors_3' 'NumberMonitors_4'\n",
      " 'NumberMonitors_More than 4'\n",
      " \"StackOverflowHasAccount_I'm not sure / I can't remember\"\n",
      " 'StackOverflowHasAccount_No' 'StackOverflowHasAccount_Yes'\n",
      " 'HoursComputer_1 - 4 hours' 'HoursComputer_5 - 8 hours'\n",
      " 'HoursComputer_9 - 12 hours' 'HoursComputer_Less than 1 hour'\n",
      " 'HoursComputer_Over 12 hours' 'HoursOutside_1 - 2 hours'\n",
      " 'HoursOutside_3 - 4 hours' 'HoursOutside_30 - 59 minutes'\n",
      " 'HoursOutside_Less than 30 minutes' 'HoursOutside_Over 4 hours']\n"
     ]
    }
   ],
   "source": [
    "X_cleaned = pd.get_dummies(X_subset_one_hot)\n",
    "print('The final, cleaned features we will train on:')\n",
    "print(X_cleaned.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export new CSV file with cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataset = y.join(X_cleaned)\n",
    "clean_dataset.to_csv('../clean_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
