{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": "# Predicting Career Satisfaction From Stack Overflow Data\n"
    },
    {
      "cell_type": "markdown",
      "source": "## Read the dataset\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        },
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": [
            "C:\\Users\\lewys\\Miniconda3\\envs\\mlfinal\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (8,12,13,14,15,16,50,51,52,53,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128) have mixed types. Specify dtype option on import or set low_memory\u003dFalse.\n  interactivity\u003dinteractivity, compiler\u003dcompiler, result\u003dresult)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "import pandas as pd\ndataset \u003d pd.read_csv(\u0027./survey_results_public.csv\u0027)\n"
    },
    {
      "cell_type": "markdown",
      "source": "## Clean the dataset\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Choose a subset of variables from the dataset for training data\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "shape before dropna:  (98855, 7)\nshape after dropna:  (43962, 7)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "X_subset \u003d dataset[[\n               # \u0027LanguageWorkedWith\u0027,\n               # \u0027DatabaseWorkedWith\u0027,\n               # \u0027PlatformWorkedWith\u0027,\n               \u0027CareerSatisfaction\u0027,\n               \u0027FrameworkWorkedWith\u0027,\n               \u0027OperatingSystem\u0027,\n               \u0027NumberMonitors\u0027,\n               \u0027StackOverflowHasAccount\u0027,\n               \u0027HoursComputer\u0027,\n               \u0027HoursOutside\u0027\n]]\n\nprint(\u0027shape before dropna: \u0027, X_subset.shape)\n# drop any rows with null data\nX_subset \u003d X_subset.dropna()\nprint(\u0027shape after dropna: \u0027, X_subset.shape)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Separate CareerSatisfaction (what we want to predict) from the rest of the columns\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "source": "# load the career satisfaction column into y\ny \u003d X_subset[\u0027CareerSatisfaction\u0027]\nX_subset \u003d X_subset.drop(\u0027CareerSatisfaction\u0027, axis\u003d1)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Each person could choose 1 of 7 ways to rate their career satisfaction.\n\nTo simplify the data for ML algorithms, we will split this single column into 7 different columns, one for each category of response.\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "(43962,)\n(43962, 7)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "print(y.shape)\ny \u003d pd.get_dummies(y)\n# notice the shape after creating dummies is (76504, 7), because get_dummies() created a new column for each category of answer in the survey\nprint(y.shape)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### For the `FrameworkWorkedWith` column, one-hot encode each answer\n\nThe responses in the `FrameworkWorkedWith` column correspond to a semicolon separated list (e.g `.NET Core;Spark`).\nThe goal of this section of the code is twofold:\n1. find all the Frameworks which respondents were able to choose from\n2. turn each string response into a one-hot encoded vector (e.g. `.NET Core;Spark` becomes `[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]`)\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [],
      "source": "def one_hot_encode(categories, data):\n    \u0027\u0027\u0027\n    takes in a list of categories and a list of data and returns a one-hot encoded vector \n    :param categories: \n    :param data: \n    :return: \n    \u0027\u0027\u0027\n    one_hot_vector \u003d [0 for _ in range(len(categories))] # initialize a vector with 0s for each category\n    for item in data:\n        for i, category in enumerate(categories):\n            if item \u003d\u003d category:\n                one_hot_vector[i] \u003d 1\n    return one_hot_vector\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [],
      "source": "# start by getting every possible category of response\n# TODO: put all this one hot encoding stuff into a function and apply it to the LanguageWorkedWith, DatabaseWorkedWIth, \u0026 PlatformWorkedWith cols\nset_of_responses \u003d set()\nfor resp in X_subset[\u0027FrameworkWorkedWith\u0027]:\n    # parse the response into a list of values\n    resp_list \u003d resp.split(\u0027;\u0027)\n    # replace the response in the dataframe with the parsed list of values\n    \n    # add to the set of total responses\n    resp_set \u003d set(resp_list)\n    set_of_responses.update(resp_set)\n# put the frameworks in alphabetical order for prettiness\nsorted_set_of_responses \u003d sorted(set_of_responses)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Now that we\u0027ve parsed all the data and found all the categories of responses for the FrameworkWorkedWith column, we can one-hot encode it easily\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "   .NET Core  Angular  Cordova  Django  Hadoop  Node.js  React  Spark  Spring  \\\n0          0        0        0       1       0        0      1      0       0   \n1          0        0        0       1       0        0      0      0       0   \n5          0        1        0       0       0        1      0      0       0   \n6          0        0        0       0       0        1      1      0       0   \n7          0        1        0       0       0        1      0      0       0   \n\n   TensorFlow  Torch/PyTorch  Xamarin  \n0           0              0        0  \n1           0              0        0  \n5           0              0        0  \n6           0              0        0  \n7           0              0        0  \n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "# iterate thru responses once more to map the list of responses into one-hot encoded columns\ndata \u003d {}\nfor i, resp in X_subset[\u0027FrameworkWorkedWith\u0027].iteritems():\n    resp_list \u003d resp.split(\u0027;\u0027)\n    one_hot_vector \u003d one_hot_encode(list(sorted_set_of_responses) , resp_list)\n    data[i] \u003d one_hot_vector\n\n# build a new dataframe that will replace the FrameworkWorkedWith column with the dict we just built\nframework_col_replacement \u003d pd.DataFrame().from_dict(data, orient\u003d\u0027index\u0027, columns\u003dlist(sorted_set_of_responses))\nprint(framework_col_replacement.head())\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Now replace the FrameworkWorkedWith column with the new one hot encoded df we just built\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "(43962, 17)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "X_subset_no_framework_col \u003d X_subset.drop(\u0027FrameworkWorkedWith\u0027, axis\u003d1)\nX_subset_one_hot \u003d pd.concat([X_subset_no_framework_col, framework_col_replacement], axis\u003d1)\nprint(X_subset_one_hot.shape)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Create dummies for the rest of the categorical variables\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "(43962, 34)\n(43962, 7)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "X_cleaned \u003d pd.get_dummies(X_subset_one_hot)\nprint(X_cleaned.shape)\nprint(y.shape)\n# print(X_cleaned.head())\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Actually fit a model now that the data is clean\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": "from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\n"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": "DecisionTreeClassifier(class_weight\u003dNone, criterion\u003d\u0027gini\u0027, max_depth\u003dNone,\n            max_features\u003dNone, max_leaf_nodes\u003dNone,\n            min_impurity_decrease\u003d0.0, min_impurity_split\u003dNone,\n            min_samples_leaf\u003d1, min_samples_split\u003d2,\n            min_weight_fraction_leaf\u003d0.0, presort\u003dFalse, random_state\u003d69,\n            splitter\u003d\u0027best\u0027)"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 36
        }
      ],
      "source": "# split into train and test sets\nX_train, X_test, y_train, y_test \u003d train_test_split(X_cleaned, y, test_size\u003d0.3)\nclf \u003d DecisionTreeClassifier(random_state\u003d69)\nclf.fit(X_train, y_train)\n"
    },
    {
      "cell_type": "markdown",
      "source": "### We can also visualize the tree\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "outputs": [],
      "source": "from sklearn.externals.six import StringIO\nfrom IPython.display import Image\nfrom sklearn.tree import export_graphviz\nimport pydotplus\n\ndot_data \u003d StringIO()\n\n#feature_names\u003dX_train.columns.values, \nexport_graphviz(clf,\n                out_file\u003ddot_data,\n                filled\u003dTrue,\n                rounded\u003dTrue,\n                special_characters\u003dTrue)\n\ngraph \u003d pydotplus.graph_from_dot_data(dot_data.getvalue())\nImage(graph.create_png())\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "pycharm-f880b5e2",
      "language": "python",
      "display_name": "PyCharm (ml-final-project-stack-overflow)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}