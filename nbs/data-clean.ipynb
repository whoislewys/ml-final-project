{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": "# Predicting Career Satisfaction From Stack Overflow Data\n"
    },
    {
      "cell_type": "markdown",
      "source": "## Read the dataset\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        },
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": [
            "C:\\Users\\lewys\\Miniconda3\\envs\\mlfinal\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (8,12,13,14,15,16,50,51,52,53,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128) have mixed types. Specify dtype option on import or set low_memory\u003dFalse.\n  interactivity\u003dinteractivity, compiler\u003dcompiler, result\u003dresult)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "import pandas as pd\ndataset \u003d pd.read_csv(\u0027./survey_results_public.csv\u0027)\n"
    },
    {
      "cell_type": "markdown",
      "source": "## Separate career satisfaction data from the rest of the columns\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "(76504, 129)\n(76504, 128)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "# remove all rows from the dataset where career satisfaction has no data\ndataset \u003d dataset[dataset[\u0027CareerSatisfaction\u0027].notnull()]\n# load the career satisfaction column into y\ny \u003d dataset[\u0027CareerSatisfaction\u0027]\n# load the the dataset minus the career satisfaction column into x\nprint(dataset.shape)\nX \u003d dataset.drop(\u0027CareerSatisfaction\u0027, axis\u003d1)\nprint(X.shape)\n"
    },
    {
      "cell_type": "markdown",
      "source": "## Create dummy variables for y\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "(76504,)\n(76504, 7)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "print(y.shape)\ny \u003d pd.get_dummies(y)\n# notice the shape after creating dummies is (76504, 7), because get_dummies() created a new column for each category of answer in the survey\nprint(y.shape)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Clean the rest of the dataset\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Choose a subset of variables from the dataset for training data\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "shape before dropna:  (76504, 9)\nshape after dropna:  (36581, 9)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "X_subset \u003d X[[\n               \u0027LanguageWorkedWith\u0027,\n               \u0027DatabaseWorkedWith\u0027,\n               \u0027PlatformWorkedWith\u0027,\n               \u0027FrameworkWorkedWith\u0027,\n               \u0027OperatingSystem\u0027,\n               \u0027NumberMonitors\u0027,\n               \u0027StackOverflowHasAccount\u0027,\n               \u0027HoursComputer\u0027,\n               \u0027HoursOutside\u0027\n]]\n\nprint(\u0027shape before dropna: \u0027, X_subset.shape)\n# drop any rows with null data\nX_subset \u003d X_subset.dropna()\nprint(\u0027shape after dropna: \u0027, X_subset.shape)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### For the `FrameworkWorkedWith` column, one-hot encode each answer\n\nThe responses in the `FrameworkWorkedWith` column correspond to a semicolon separated list (e.g `.NET Core;Spark`).\nThe goal of this section of the code is twofold:\n1. find all the Frameworks which respondents were able to choose from\n2. turn each string response into a one-hot encoded vector (e.g. `.NET Core;Spark` becomes `[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]`)\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "outputs": [],
      "source": "def one_hot_encode(categories, data):\n    \u0027\u0027\u0027\n    takes in a list of categories and a list of data and returns a one-hot encoded vector \n    :param categories: \n    :param data: \n    :return: \n    \u0027\u0027\u0027\n    one_hot_vector \u003d [0 for _ in range(len(categories))] # initialize a vector with 0s for each category\n    for item in data:\n        for i, category in enumerate(categories):\n            if item \u003d\u003d category:\n                one_hot_vector[i] \u003d 1\n    return one_hot_vector\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "outputs": [],
      "source": "# start by getting every possible category of response\nset_of_responses \u003d set()\nfor resp in X_subset[\u0027FrameworkWorkedWith\u0027]:\n    # parse the response into a list of values\n    resp_list \u003d resp.split(\u0027;\u0027)\n    # replace the response in the dataframe with the parsed list of values\n    \n    # add to the set of total responses\n    resp_set \u003d set(resp_list)\n    set_of_responses.update(resp_set)\n# put the frameworks in alphabetical order for prettiness\nsorted_set_of_responses \u003d sorted(set_of_responses)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Now that we\u0027ve parsed all the data and found all the categories of responses for the FrameworkWorkedWith column, we can one-hot encode it easily\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "   .NET Core  Angular  Cordova  Django  Hadoop  Node.js  React  Spark  Spring  \\\n0          0        0        0       1       0        0      1      0       0   \n1          0        0        0       1       0        0      0      0       0   \n5          0        1        0       0       0        1      0      0       0   \n6          0        0        0       0       0        1      1      0       0   \n7          0        1        0       0       0        1      0      0       0   \n\n   TensorFlow  Torch/PyTorch  Xamarin  \n0           0              0        0  \n1           0              0        0  \n5           0              0        0  \n6           0              0        0  \n7           0              0        0  \n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "# iterate thru responses once more to map the list of responses into one-hot encoded columns\ndata \u003d {}\nfor i, resp in X_subset[\u0027FrameworkWorkedWith\u0027].iteritems():\n    resp_list \u003d resp.split(\u0027;\u0027)\n    one_hot_vector \u003d one_hot_encode(list(sorted_set_of_responses) , resp_list)\n    data[i] \u003d one_hot_vector\n\n# build a new dataframe that will replace the FrameworkWorkedWith column with the dict we just built\nframework_col_replacement \u003d pd.DataFrame().from_dict(data, orient\u003d\u0027index\u0027, columns\u003dlist(sorted_set_of_responses))\nprint(framework_col_replacement.head())\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Now replace the FrameworkWorkedWith column with the new one hot encoded df we just built\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "before framework df (36581, 8)\n                           LanguageWorkedWith  \\\n0                  JavaScript;Python;HTML;CSS   \n1                JavaScript;Python;Bash/Shell   \n5  Java;JavaScript;Python;TypeScript;HTML;CSS   \n6                         JavaScript;HTML;CSS   \n7              JavaScript;TypeScript;HTML;CSS   \n\n                                  DatabaseWorkedWith  \\\n0  Redis;SQL Server;MySQL;PostgreSQL;Amazon RDS/A...   \n1                         Redis;PostgreSQL;Memcached   \n5                                            MongoDB   \n6                                            MongoDB   \n7  MongoDB;MySQL;Microsoft Azure (Tables, CosmosD...   \n\n         PlatformWorkedWith OperatingSystem NumberMonitors  \\\n0  AWS;Azure;Linux;Firebase     Linux-based              1   \n1                     Linux     Linux-based              2   \n5                     Linux     Linux-based              2   \n6                     Linux           MacOS              2   \n7              Azure;Heroku         Windows              1   \n\n  StackOverflowHasAccount  HoursComputer          HoursOutside  \n0                     Yes   9 - 12 hours           1 - 2 hours  \n1                     Yes    5 - 8 hours       30 - 59 minutes  \n5                     Yes   9 - 12 hours       30 - 59 minutes  \n6                     Yes  Over 12 hours  Less than 30 minutes  \n7                     Yes  Over 12 hours           1 - 2 hours  \nwith new framework df:  (36581, 20)\n                           LanguageWorkedWith  \\\n0                  JavaScript;Python;HTML;CSS   \n1                JavaScript;Python;Bash/Shell   \n5  Java;JavaScript;Python;TypeScript;HTML;CSS   \n6                         JavaScript;HTML;CSS   \n7              JavaScript;TypeScript;HTML;CSS   \n\n                                  DatabaseWorkedWith  \\\n0  Redis;SQL Server;MySQL;PostgreSQL;Amazon RDS/A...   \n1                         Redis;PostgreSQL;Memcached   \n5                                            MongoDB   \n6                                            MongoDB   \n7  MongoDB;MySQL;Microsoft Azure (Tables, CosmosD...   \n\n         PlatformWorkedWith OperatingSystem NumberMonitors  \\\n0  AWS;Azure;Linux;Firebase     Linux-based              1   \n1                     Linux     Linux-based              2   \n5                     Linux     Linux-based              2   \n6                     Linux           MacOS              2   \n7              Azure;Heroku         Windows              1   \n\n  StackOverflowHasAccount  HoursComputer          HoursOutside  .NET Core  \\\n0                     Yes   9 - 12 hours           1 - 2 hours          0   \n1                     Yes    5 - 8 hours       30 - 59 minutes          0   \n5                     Yes   9 - 12 hours       30 - 59 minutes          0   \n6                     Yes  Over 12 hours  Less than 30 minutes          0   \n7                     Yes  Over 12 hours           1 - 2 hours          0   \n\n   Angular  Cordova  Django  Hadoop  Node.js  React  Spark  Spring  \\\n0        0        0       1       0        0      1      0       0   \n1        0        0       1       0        0      0      0       0   \n5        1        0       0       0        1      0      0       0   \n6        0        0       0       0        1      1      0       0   \n7        1        0       0       0        1      0      0       0   \n\n   TensorFlow  Torch/PyTorch  Xamarin  \n0           0              0        0  \n1           0              0        0  \n5           0              0        0  \n6           0              0        0  \n7           0              0        0  \n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "X_subset_no_framework_col \u003d X_subset.drop(\u0027FrameworkWorkedWith\u0027, axis\u003d1)\nprint(\u0027before framework df\u0027, X_subset_no_framework_col.shape)\nprint(X_subset_no_framework_col.head())\nX_subset_one_hot \u003d pd.concat([X_subset_no_framework_col, framework_col_replacement], axis\u003d1)\nprint(\u0027with new framework df: \u0027, X_subset_one_hot.shape)\nprint(X_subset_one_hot.head())\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Actually fit a model now that the data is clean\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import train_test_split"
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": "X_train, X_test, y_train, y_test \u003d train_test_split(X, y, test_size\u003d0.3)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "# print(X.sum(axis\u003d1))\n",
        "X_smol \u003d X[:500]\n",
        "print(X_smol.shape)\n",
        "print(X_smol.columns[X_smol.sum() \u003d\u003d 1])\n",
        "# print(X.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "sel \u003d SelectFromModel(RandomForestClassifier(n_estimators\u003d100))\n",
        "sel.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "pycharm-f880b5e2",
      "language": "python",
      "display_name": "PyCharm (ml-final-project-stack-overflow)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}